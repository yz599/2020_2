{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Generated data\n",
    "Scikit-learn contains the following convenience functions for generating data:\n",
    "\n",
    "- sklearn.datasets.make_regression()\n",
    "- sklearn.datasets.make_classification()\n",
    "- sklearn.datasets.make_moons()\n",
    "\n",
    "The following codes generates a regression data set with 3 features, 100 observations, and a random seed of 1:\n",
    "\n",
    "The function make_regression() returns a tuple of two NumPy objects. The features are stored in the first NumPy array and the labels in the second NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data=make_regression(n_features=3,n_samples=100,random_state=1)\n",
    "features=pd.DataFrame(data[0])\n",
    "labels=pd.Series(data[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Fitting a network\n",
    "two different approaches to training a linear regression model:\n",
    "- gradient descent and\n",
    "- ordinary least squares.\n",
    "\n",
    "Gradient descent is the most common technique for fitting neural network models and we'll explore it in further detail in the third mission. Because we've implemented gradient descent before in the Linear Regression for Machine Learning course, we'll rely on the scikit-learn implementation of gradient descent in this mission.\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "          0         1         2  bias\n0  1.293226 -0.617362 -0.110447     1\n1 -2.793085  0.366332  1.937529     1\n2  0.801861 -0.186570  0.046567     1\n3  0.129102  0.502741  1.616950     1\n4 -0.691661 -0.687173 -0.396754     1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>bias</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.293226</td>\n      <td>-0.617362</td>\n      <td>-0.110447</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-2.793085</td>\n      <td>0.366332</td>\n      <td>1.937529</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.801861</td>\n      <td>-0.186570</td>\n      <td>0.046567</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.129102</td>\n      <td>0.502741</td>\n      <td>1.616950</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.691661</td>\n      <td>-0.687173</td>\n      <td>-0.396754</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['bias']=1\n",
    "\n",
    "features.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "def train(features,labels):\n",
    "    lr=SGDRegressor()\n",
    "    lr.fit(features,labels)\n",
    "    weights=lr.coef_\n",
    "    return weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def feedforward(features,weights):\n",
    "    predictions=np.dot(features,weights.T)\n",
    "    return predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "train_weights = train(features, labels)\n",
    "linear_predictions = feedforward(features, train_weights)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
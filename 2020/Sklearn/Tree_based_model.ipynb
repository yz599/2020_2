{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is based on [datacamp tutorial](https://campus.datacamp.com/courses/machine-learning-with-tree-based-models-in-python/classification-and-regression-trees?ex=2)\n",
    "Notes could be found [here](https://bourbon0212.github.io/DataCamp-Practice/Python/Machine%20Learning%20with%20Tree-Based%20Models%20in%20Python/Machine-Learning-with-Tree-Based-Models-in-Python.html#ensemble_learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **classification tree**: divides the **feature space** into **rectangular regions.**\n",
    "In contrast, a **linear model**: such as logistic regression produces only a **single linear decision boundary** dividing the feature space into two decision regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data=pd.read_csv(\"data.csv\",usecols=[\"radius_mean\",\"concave points_mean\",\"diagnosis\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop(\"diagnosis\",axis=1)\n",
    "y=data[\"diagnosis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,stratify=y,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DT  classifer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy vs Gini index\n",
    "The gini index is slightly \n",
    "- **faster** to compute and \n",
    "- is the **default criterion** used in the DecisionTreeClassifier model of scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=8, random_state=1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_entropy=DecisionTreeClassifier(max_depth=8,criterion=\"entropy\",random_state=1)\n",
    "dt_entropy.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=8, random_state=1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_gini=DecisionTreeClassifier(max_depth=8,criterion=\"gini\",random_state=1)\n",
    "dt_gini.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_entr=dt_entropy.predict(X_test)\n",
    "y_pred_gini=dt_gini.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate DT\n",
    "\n",
    "accuracy metric which corresponds to the **fraction of correct predictions** made on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_entropy=accuracy_score(y_test,y_pred_entr)\n",
    "acc_gini=accuracy_score(y_test,y_pred_gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy achieved by using entropy:  0.8859649122807017\n",
      "Accuracy achieved by using entropy:  0.9210526315789473\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy achieved by using entropy: ', acc_entropy)\n",
    "print('Accuracy achieved by using entropy: ', acc_gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg=LogisticRegression(random_state=1)\n",
    "logreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2=logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy of LOgistic regression: 0.89\n"
     ]
    }
   ],
   "source": [
    "acc2=accuracy_score(y_test,y_pred2)\n",
    "print(\"Test set accuracy of LOgistic regression: {:.2f}\".format(acc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization and compare with Logit Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DT regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>displ</th>\n",
       "      <th>hp</th>\n",
       "      <th>weight</th>\n",
       "      <th>accel</th>\n",
       "      <th>origin</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>88</td>\n",
       "      <td>3139</td>\n",
       "      <td>14.5</td>\n",
       "      <td>US</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>193</td>\n",
       "      <td>4732</td>\n",
       "      <td>18.5</td>\n",
       "      <td>US</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.1</td>\n",
       "      <td>91.0</td>\n",
       "      <td>60</td>\n",
       "      <td>1800</td>\n",
       "      <td>16.4</td>\n",
       "      <td>Asia</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.5</td>\n",
       "      <td>250.0</td>\n",
       "      <td>98</td>\n",
       "      <td>3525</td>\n",
       "      <td>19.0</td>\n",
       "      <td>US</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.3</td>\n",
       "      <td>97.0</td>\n",
       "      <td>78</td>\n",
       "      <td>2188</td>\n",
       "      <td>15.8</td>\n",
       "      <td>Europe</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  displ   hp  weight  accel  origin  size\n",
       "0  18.0  250.0   88    3139   14.5      US  15.0\n",
       "1   9.0  304.0  193    4732   18.5      US  20.0\n",
       "2  36.1   91.0   60    1800   16.4    Asia  10.0\n",
       "3  18.5  250.0   98    3525   19.0      US  15.0\n",
       "4  34.3   97.0   78    2188   15.8  Europe  10.0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpg=pd.read_csv(\"auto.csv\")\n",
    "mpg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --------------------------Prep data-----------------\n",
    "mpg_train=pd.get_dummies(mpg,columns=[\"origin\"],prefix=\"origin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --------------------------Splitting-----------------\n",
    "X=mpg_train.drop([\"mpg\"],axis=1)\n",
    "y=mpg_train[\"mpg\"]\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --------------------------Fit model------------------\n",
    "dt=DecisionTreeRegressor(max_depth=8,min_samples_leaf=0.13,random_state=3)\n",
    "dt.fit(X_train,y_train)\n",
    "y_pred=dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of dt: 4.27\n"
     ]
    }
   ],
   "source": [
    "## --------------------------Evaluate the performace-------\n",
    "mse_dt=MSE(y_test,y_pred)\n",
    "rmse_dt=np.sqrt(mse_dt)\n",
    "print(\"Test set RMSE of dt: {:.2f}\".format(rmse_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LinearRegression()\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of dt: 3.98\n"
     ]
    }
   ],
   "source": [
    "y_pred_lr=lr.predict(X_test)\n",
    "mse_lr=MSE(y_test,y_pred_lr)\n",
    "rmse_lr=np.sqrt(mse_lr)\n",
    "print(\"Test set RMSE of dt: {:.2f}\".format(rmse_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=1)\n",
    "dt2=DecisionTreeRegressor(max_depth=4,min_samples_leaf=0.26,random_state=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RMSE: 5.14\n"
     ]
    }
   ],
   "source": [
    "MSE_CV_scores=-cross_val_score(dt2,X_train,y_train,cv=10,\n",
    "                             scoring=\"neg_mean_squared_error\",\n",
    "                             n_jobs=-1)\n",
    "RMSE_CV=(MSE_CV_scores.mean())**(0.5)\n",
    "print('CV RMSE: {:.2f}'.format(RMSE_CV))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=4, min_samples_leaf=0.26)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RMSE: 5.15\n"
     ]
    }
   ],
   "source": [
    "y_pred_train=dt2.predict(X_train)\n",
    "RMSE_train=MSE(y_train,y_pred_train)**(0.5)\n",
    "print('CV RMSE: {:.2f}'.format(RMSE_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dt suffers from **high bias** because **RMSE_CV â‰ˆ RMSE_train**  \n",
    "\n",
    "- dt is indeed **underfitting the training set** as the model is too constrained to capture the **nonlinear dependencies** between features and labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indian_liver_classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"indian_liver_patient/indian_liver_patient_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Age_std</th>\n",
       "      <th>Total_Bilirubin_std</th>\n",
       "      <th>Direct_Bilirubin_std</th>\n",
       "      <th>Alkaline_Phosphotase_std</th>\n",
       "      <th>Alamine_Aminotransferase_std</th>\n",
       "      <th>Aspartate_Aminotransferase_std</th>\n",
       "      <th>Total_Protiens_std</th>\n",
       "      <th>Albumin_std</th>\n",
       "      <th>Albumin_and_Globulin_Ratio_std</th>\n",
       "      <th>Is_male_std</th>\n",
       "      <th>Liver_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.247403</td>\n",
       "      <td>-0.420320</td>\n",
       "      <td>-0.495414</td>\n",
       "      <td>-0.428870</td>\n",
       "      <td>-0.355832</td>\n",
       "      <td>-0.319111</td>\n",
       "      <td>0.293722</td>\n",
       "      <td>0.203446</td>\n",
       "      <td>-0.147390</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.062306</td>\n",
       "      <td>1.218936</td>\n",
       "      <td>1.423518</td>\n",
       "      <td>1.675083</td>\n",
       "      <td>-0.093573</td>\n",
       "      <td>-0.035962</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>0.077462</td>\n",
       "      <td>-0.648461</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.062306</td>\n",
       "      <td>0.640375</td>\n",
       "      <td>0.926017</td>\n",
       "      <td>0.816243</td>\n",
       "      <td>-0.115428</td>\n",
       "      <td>-0.146459</td>\n",
       "      <td>0.478274</td>\n",
       "      <td>0.203446</td>\n",
       "      <td>-0.178707</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.815511</td>\n",
       "      <td>-0.372106</td>\n",
       "      <td>-0.388807</td>\n",
       "      <td>-0.449416</td>\n",
       "      <td>-0.366760</td>\n",
       "      <td>-0.312205</td>\n",
       "      <td>0.293722</td>\n",
       "      <td>0.329431</td>\n",
       "      <td>0.165780</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.679294</td>\n",
       "      <td>0.093956</td>\n",
       "      <td>0.179766</td>\n",
       "      <td>-0.395996</td>\n",
       "      <td>-0.295731</td>\n",
       "      <td>-0.177537</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>-0.930414</td>\n",
       "      <td>-1.713237</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   Age_std  Total_Bilirubin_std  Direct_Bilirubin_std  \\\n",
       "0           0  1.247403            -0.420320             -0.495414   \n",
       "1           1  1.062306             1.218936              1.423518   \n",
       "2           2  1.062306             0.640375              0.926017   \n",
       "3           3  0.815511            -0.372106             -0.388807   \n",
       "4           4  1.679294             0.093956              0.179766   \n",
       "\n",
       "   Alkaline_Phosphotase_std  Alamine_Aminotransferase_std  \\\n",
       "0                 -0.428870                     -0.355832   \n",
       "1                  1.675083                     -0.093573   \n",
       "2                  0.816243                     -0.115428   \n",
       "3                 -0.449416                     -0.366760   \n",
       "4                 -0.395996                     -0.295731   \n",
       "\n",
       "   Aspartate_Aminotransferase_std  Total_Protiens_std  Albumin_std  \\\n",
       "0                       -0.319111            0.293722     0.203446   \n",
       "1                       -0.035962            0.939655     0.077462   \n",
       "2                       -0.146459            0.478274     0.203446   \n",
       "3                       -0.312205            0.293722     0.329431   \n",
       "4                       -0.177537            0.755102    -0.930414   \n",
       "\n",
       "   Albumin_and_Globulin_Ratio_std  Is_male_std  Liver_disease  \n",
       "0                       -0.147390            0              1  \n",
       "1                       -0.648461            1              1  \n",
       "2                       -0.178707            1              1  \n",
       "3                        0.165780            1              1  \n",
       "4                       -1.713237            1              1  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 579 entries, 0 to 578\n",
      "Data columns (total 12 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   Unnamed: 0                      579 non-null    int64  \n",
      " 1   Age_std                         579 non-null    float64\n",
      " 2   Total_Bilirubin_std             579 non-null    float64\n",
      " 3   Direct_Bilirubin_std            579 non-null    float64\n",
      " 4   Alkaline_Phosphotase_std        579 non-null    float64\n",
      " 5   Alamine_Aminotransferase_std    579 non-null    float64\n",
      " 6   Aspartate_Aminotransferase_std  579 non-null    float64\n",
      " 7   Total_Protiens_std              579 non-null    float64\n",
      " 8   Albumin_std                     579 non-null    float64\n",
      " 9   Albumin_and_Globulin_Ratio_std  579 non-null    float64\n",
      " 10  Is_male_std                     579 non-null    int64  \n",
      " 11  Liver_disease                   579 non-null    int64  \n",
      "dtypes: float64(9), int64(3)\n",
      "memory usage: 54.4 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop([\"Liver_disease\"],axis=1)\n",
    "y=data[\"Liver_disease\"]\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,stratify=y,\n",
    "                                               random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance of different classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression(random_state=SEED)\n",
    "knn=KNN(n_neighbors=27)\n",
    "dt=DecisionTreeClassifier(min_samples_leaf=0.13,random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [('Logistic Regression', lr), ('K Nearest Neighbours', knn), ('Classification Tree', dt)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll do so by fitting each classifier on the training set and evaluating its test set accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:0.764\n",
      "K Nearest Neighbours:0.724\n",
      "Classification Tree:0.730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yunzhang/Applications/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "for clf_name,clf in classifiers:\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    print(\"{:s}:{:.3f}\".format(clf_name,accuracy_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voting Classifier\n",
    "Finally, you'll evaluate the performance of a voting classifier that takes the outputs of the models defined in the list classifiers and assigns labels by majority voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yunzhang/Applications/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('Logistic Regression',\n",
       "                              LogisticRegression(random_state=1)),\n",
       "                             ('K Nearest Neighbours',\n",
       "                              KNeighborsClassifier(n_neighbors=27)),\n",
       "                             ('Classification Tree',\n",
       "                              DecisionTreeClassifier(min_samples_leaf=0.13,\n",
       "                                                     random_state=1))])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc=VotingClassifier(estimators=classifiers)\n",
    "vc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier: 0.764\n"
     ]
    }
   ],
   "source": [
    "y_pred_vc=vc.predict(X_test)\n",
    "accuracy_vc=accuracy_score(y_test,y_pred_vc)\n",
    "print('Voting Classifier: {:.3f}'.format(accuracy_vc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=DecisionTreeClassifier(random_state=1)\n",
    "bc=BaggingClassifier(base_estimator=dt,n_estimators=50,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc.fit(X_train,y_train)\n",
    "y_pred=bc.predict(X_test)\n",
    "acc_test=accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy of bc: 0.69\n"
     ]
    }
   ],
   "source": [
    "print('Test set accuracy of bc: {:.2f}'.format(acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### OOB accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=DecisionTreeClassifier(min_samples_leaf=8,\n",
    "                          random_state=1)\n",
    "bc=BaggingClassifier(base_estimator=dt,n_estimators=50,oob_score=True,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### OOB Score vs Test Set Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.684, OOB accuracy: 0.694\n"
     ]
    }
   ],
   "source": [
    "bc.fit(X_train,y_train)\n",
    "y_pred=bc.predict(X_test)\n",
    "acc_test=accuracy_score(y_test,y_pred)\n",
    "acc_oob=bc.oob_score_\n",
    "print('Test set accuracy: {:.3f}, OOB accuracy: {:.3f}'.format(acc_test, acc_oob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test set accuracy and the OOB accuracy of bc are both roughly equal to 70%!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "dt=DecisionTreeClassifier(max_depth=2,random_state=1)\n",
    "ada=AdaBoostClassifier(base_estimator=dt,n_estimators=180,random_state=1)\n",
    "data=pd.read_csv(\"indian_liver_patient/indian_liver_patient_preprocessed.csv\")\n",
    "\n",
    "X=data.drop([\"Liver_disease\"],axis=1)\n",
    "y=data[\"Liver_disease\"]\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,\n",
    "                                               random_state=1)\n",
    "ada.fit(X_train,y_train)\n",
    "y_pred_proba =ada.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ROC_AUC score\n",
    "In addition, given that this dataset is imbalanced, you'll be using the ROC AUC score as a metric instead of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "ada_roc_auc=roc_auc_score(y_test,y_pred_proba)\n",
    "print('ROC AUC score: {:.2f}'.format(ada_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set the tree's hyperparameter grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=DecisionTreeClassifier()\n",
    "params_dt={\"max_depth\":[2,3,4],\n",
    "          \"min_samples_leaf\":[0.12,0.14,0.16,0.18]}\n",
    "grid_dt=GridSearchCV(estimator=dt,\n",
    "                     param_grid=params_dt,\n",
    "                     scoring='roc_auc',\n",
    "                    cv=5,\n",
    "                    n_jobs=-1)\n",
    "grid_dt.fit(X_train,y_train)\n",
    "best_model = grid_dt.best_estimator_\n",
    "y_pred_proba=best_model.predict_proba(X_test)[:,1]\n",
    "test_roc_auc=roc_auc_score(y_test,y_pred_proba)\n",
    "print('Test set ROC AUC score: {:.3f}'.format(test_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bike_regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Random forest - regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"bikes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cnt</th>\n",
       "      <th>instant</th>\n",
       "      <th>mnth</th>\n",
       "      <th>yr</th>\n",
       "      <th>Clear to partly cloudy</th>\n",
       "      <th>Light Precipitation</th>\n",
       "      <th>Misty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>149</td>\n",
       "      <td>13004</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>93</td>\n",
       "      <td>13005</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.0896</td>\n",
       "      <td>90</td>\n",
       "      <td>13006</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>33</td>\n",
       "      <td>13007</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>4</td>\n",
       "      <td>13008</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hr  holiday  workingday  temp   hum  windspeed  cnt  instant  mnth  yr  \\\n",
       "0   0        0           0  0.76  0.66     0.0000  149    13004     7   1   \n",
       "1   1        0           0  0.74  0.70     0.1343   93    13005     7   1   \n",
       "2   2        0           0  0.72  0.74     0.0896   90    13006     7   1   \n",
       "3   3        0           0  0.72  0.84     0.1343   33    13007     7   1   \n",
       "4   4        0           0  0.70  0.79     0.1940    4    13008     7   1   \n",
       "\n",
       "   Clear to partly cloudy  Light Precipitation  Misty  \n",
       "0                       1                    0      0  \n",
       "1                       1                    0      0  \n",
       "2                       1                    0      0  \n",
       "3                       1                    0      0  \n",
       "4                       1                    0      0  "
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop([\"cnt\"],axis=1)\n",
    "y=data[\"cnt\"]\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,\n",
    "                                               random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=25, random_state=2)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=RandomForestRegressor(n_estimators=25,random_state=2)\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of rf: 50.01\n"
     ]
    }
   ],
   "source": [
    "y_pred=rf.predict(X_test)\n",
    "rmse_test=MSE(y_test,y_pred)**(0.5)\n",
    "print('Test set RMSE of rf: {:.2f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can try training a single CART on the same dataset. The test set RMSE achieved by rf is significantly smaller than that achieved by a single CART!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature importance\n",
    "you'll determine which features were the most predictive according to the random forests regressor rf that you trained in a previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances=pd.Series(rf.feature_importances_,index=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances_sorted=importances.sort_values()\n",
    "importances_sorted.plot(kind='barh',color='lightgreen')\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, hr and workingday are the most important features according to rf. The importances of these two features add up to more than 90%!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient boost regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of rf: 43.11\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gb=GradientBoostingRegressor(max_depth=4,n_estimators=200,random_state=2)\n",
    "\n",
    "gb.fit(X_train,y_train)\n",
    "y_pred=gd.predict(X_test)\n",
    "RMSE=MSE(y_test,y_pred)**(0.5)\n",
    "print('Test set RMSE of rf: {:.2f}'.format(RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic Gradient Boosting regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgbr = GradientBoostingRegressor(max_depth=4, \n",
    "            subsample=0.9,\n",
    "            max_features=0.75,\n",
    "            n_estimators=200,                                \n",
    "            random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(max_depth=4, max_features=0.75, n_estimators=200,\n",
       "                          random_state=2, subsample=0.9)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgbr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of sgbr: 46.816\n"
     ]
    }
   ],
   "source": [
    "y_pred=sgbr.predict(X_test)\n",
    "mse_test = MSE(y_test,y_pred)\n",
    "rmse_test = mse_test**(0.5)\n",
    "print('Test set RMSE of sgbr: {:.3f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of DecisionTreeClassifier(max_depth=2, random_state=1)>"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"indian_liver_patient/indian_liver_patient_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop([\"Liver_disease\"],axis=1)\n",
    "y=data[\"Liver_disease\"]\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,stratify=y,\n",
    "                                               random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### check parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'criterion': 'mse',\n",
       " 'max_depth': None,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'presort': 'deprecated',\n",
       " 'random_state': None,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=DecisionTreeRegressor()\n",
    "rf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set the hyperparameter grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_rf ={\"n_estimators\":[100,350,500],\n",
    "           \"max_features\":[\"log2\",\"auto\",\"sqrt\"],\n",
    "           \"min_samples_leaf\":[2,10,30]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_rf = GridSearchCV(estimator=rf,\n",
    "                       param_grid=params_rf,\n",
    "                       scoring=\"neg_mean_squared_error\",\n",
    "                       cv=3,\n",
    "                       verbose=1,\n",
    "                       n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter n_estimators for estimator DecisionTreeRegressor(max_features='log2', min_samples_leaf=2). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/yunzhang/Applications/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 431, in _process_worker\n    r = call_item()\n  File \"/Users/yunzhang/Applications/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 285, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/Users/yunzhang/Applications/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/yunzhang/Applications/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"/Users/yunzhang/Applications/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/Users/yunzhang/Applications/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 520, in _fit_and_score\n    estimator = estimator.set_params(**cloned_parameters)\n  File \"/Users/yunzhang/Applications/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 249, in set_params\n    raise ValueError('Invalid parameter %s for estimator %s. '\nValueError: Invalid parameter n_estimators for estimator DecisionTreeRegressor(max_features='log2', min_samples_leaf=2). Check the list of available parameters with `estimator.get_params().keys()`.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-273-52ded35b3002>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid_rf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter n_estimators for estimator DecisionTreeRegressor(max_features='log2', min_samples_leaf=2). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "grid_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_rf.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "rmse_test = MSE(y_test,y_pred)**(0.5)\n",
    "print('Test RMSE of best model: {:.3f}'.format(rmse_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "241px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
